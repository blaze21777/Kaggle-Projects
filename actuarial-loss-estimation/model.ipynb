{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The challenge is to predict Workers Compensation claims using highly realistic synthetic data.\n",
    "\n",
    " The evaluation method is Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "# Disable scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.9f' % x)\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", parse_dates=[\"DateReported\", \"DateTimeOfAccident\"])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan values with unknown \n",
    "df[\"MaritalStatus\"] = df[\"MaritalStatus\"].fillna('Unknown')\n",
    "df[\"MaritalStatus\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Gender\", \"MaritalStatus\", \"PartTimeFullTime\"]] = df[\n",
    "    [\"Gender\", \"MaritalStatus\", \"PartTimeFullTime\"]\n",
    "].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DateOfAccident\"] = df[\"DateTimeOfAccident\"].dt.date\n",
    "df[\"TimeOfAccident\"] = df[\"DateTimeOfAccident\"].dt.time\n",
    "\n",
    "col_index = df.columns.get_loc(\"DateTimeOfAccident\")\n",
    "\n",
    "# make sure it's int to suppress error\n",
    "if not isinstance(col_index, int):\n",
    "    raise ValueError(\"`datetime_col_index` must be an integer.\")\n",
    "\n",
    "df.insert(col_index + 1, \"DateOfAccident\", df.pop(\"DateOfAccident\"))\n",
    "df.insert(col_index + 2, \"TimeOfAccident\", df.pop(\"TimeOfAccident\"))\n",
    "\n",
    "df[\"DateOfAccident\"] = pd.to_datetime(df[\"DateOfAccident\"], format=\"ISO8601\", utc=True)\n",
    "# df[\"TimeOfAccident\"] = pd.to_datetime(df[\"TimeOfAccident\"], format=\"%H:%M:%S\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to format a model can understand\n",
    "df[\"AccidentDay\"] = df[\"DateTimeOfAccident\"].dt.day\n",
    "df[\"AccidentMonth\"] = df[\"DateTimeOfAccident\"].dt.month\n",
    "df[\"AccidentYear\"] = df[\"DateTimeOfAccident\"].dt.year\n",
    "df[\"AccidentWeekday\"] = df[\"DateTimeOfAccident\"].dt.weekday\n",
    "df[\"ReportedDay\"] = df[\"DateReported\"].dt.day\n",
    "df[\"ReportedMonth\"] = df[\"DateReported\"].dt.month\n",
    "df[\"ReportedYear\"] = df[\"DateReported\"].dt.year\n",
    "df[\"ReportedWeekday\"] = df[\"DateReported\"].dt.weekday\n",
    "df[\"DaysToReportAccident\"] = (df.DateReported - df.DateOfAccident).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"LogInitialIncurredCalimsCost\", \"LogUltimateIncurredClaimCost\"]] = np.log1p(\n",
    "    df[[\"InitialIncurredCalimsCost\", \"UltimateIncurredClaimCost\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"LogInitialIncurredCalimsCost\", \"LogUltimateIncurredClaimCost\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"InitialIncurredCalimsCost\", \"UltimateIncurredClaimCost\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def text_clean(claim):\n",
    "    # Converting to Lower Case\n",
    "    claim = claim.lower()\n",
    "    # Getting List Of Words\n",
    "    claim = claim.split()\n",
    "    # Removing Stop Words(Words which do not add any information like =is,are,I etc)\n",
    "    claim = [word for word in claim if word not in stops]\n",
    "    # Stemming the word(words like playing ,played are replaced with play)\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stem_claim = [porter_stemmer.stem(word) for word in claim]\n",
    "\n",
    "    # Lemmatizing the words (replacing words with their base form)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_claim = [lemmatizer.lemmatize(word) for word in claim]\n",
    "    return lem_claim, stem_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ClaimDescriptionClean\"] = df[\"ClaimDescription\"].apply(\n",
    "    lambda x: \" \".join(text_clean(x)[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_descriptions = [claim.split() for claim in df[\"ClaimDescriptionClean\"]]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(\n",
    "    sentences=tokenized_descriptions,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    ")\n",
    "\n",
    "\n",
    "def create_embedding(claim):\n",
    "    words = claim.split()\n",
    "    embeddings = [model.wv[word] for word in words if word in model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ClaimDescriptionEmbedding\"] = df[\"ClaimDescriptionClean\"].apply(create_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.array([embedding for embedding in df[\"ClaimDescriptionEmbedding\"]])\n",
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(all_embeddings)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "df[\"ClusterLabel\"] = cluster_labels\n",
    "\n",
    "# View some claims from each cluster\n",
    "for cluster in range(5):\n",
    "    print(f\"\\nCluster {cluster} claims:\")\n",
    "    print(df[df[\"ClusterLabel\"] == cluster][\"ClaimDescriptionClean\"].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(\n",
    "    df[\n",
    "        [\n",
    "            # \"ClaimNumber\",\n",
    "            # \"DateTimeOfAccident\",\n",
    "            # \"DateOfAccident\",\n",
    "            # \"TimeOfAccident\",\n",
    "            # \"DateReported\",\n",
    "            \"Age\",\n",
    "            \"Gender\",\n",
    "            \"MaritalStatus\",\n",
    "            \"DependentChildren\",\n",
    "            \"DependentsOther\",\n",
    "            \"WeeklyWages\",\n",
    "            \"PartTimeFullTime\",\n",
    "            \"HoursWorkedPerWeek\",\n",
    "            \"DaysWorkedPerWeek\",\n",
    "            # \"ClaimDescription\",\n",
    "            \"InitialIncurredCalimsCost\",\n",
    "            \"UltimateIncurredClaimCost\",\n",
    "            # \"LogInitialIncurredCalimsCost\",\n",
    "            # \"LogUltimateIncurredClaimCost\",\n",
    "            \"AccidentDay\",\n",
    "            \"AccidentMonth\",\n",
    "            \"AccidentYear\",\n",
    "            \"AccidentWeekday\",\n",
    "            \"ReportedDay\",\n",
    "            \"ReportedMonth\",\n",
    "            \"ReportedYear\",\n",
    "            \"ReportedWeekday\",\n",
    "            #\"ClaimDescriptionClean\",\n",
    "            #\"ClaimDescriptionEmbedding\",\n",
    "            \"ClusterLabel\",\n",
    "            \n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.get_dummies(\n",
    "    df[\n",
    "        [\n",
    "            # \"ClaimNumber\",\n",
    "            # \"DateTimeOfAccident\",\n",
    "            # \"DateOfAccident\",\n",
    "            # \"TimeOfAccident\",\n",
    "            # \"DateReported\",\n",
    "            \"Age\",\n",
    "            \"Gender\",\n",
    "            \"MaritalStatus\",\n",
    "            \"DependentChildren\",\n",
    "            \"DependentsOther\",\n",
    "            \"WeeklyWages\",\n",
    "            \"PartTimeFullTime\",\n",
    "            \"HoursWorkedPerWeek\",\n",
    "            \"DaysWorkedPerWeek\",\n",
    "            # \"ClaimDescription\",\n",
    "            # \"InitialIncurredCalimsCost\",\n",
    "            #\"UltimateIncurredClaimCost\",\n",
    "            \"LogInitialIncurredCalimsCost\",\n",
    "            \"LogUltimateIncurredClaimCost\",\n",
    "            \"AccidentDay\",\n",
    "            \"AccidentMonth\",\n",
    "            \"AccidentYear\",\n",
    "            \"AccidentWeekday\",\n",
    "            \"ReportedDay\",\n",
    "            \"ReportedMonth\",\n",
    "            \"ReportedYear\",\n",
    "            \"ReportedWeekday\",\n",
    "            #\"ClaimDescriptionClean\",\n",
    "            #\"ClaimDescriptionEmbedding\",\n",
    "            \"ClusterLabel\",\n",
    "            \n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "df_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(\n",
    "    columns=[\"UltimateIncurredClaimCost\"]#, \n",
    ")\n",
    "y = df_encoded[\"UltimateIncurredClaimCost\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = df_scaled.drop(\n",
    "    columns=[\"LogUltimateIncurredClaimCost\"]#, \n",
    ")\n",
    "ys = df_scaled[\"LogUltimateIncurredClaimCost\"]\n",
    "\n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(\n",
    "    Xs, ys, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",  # Regression objective\n",
    "    \"n_estimators\": 100,  # Number of trees (boosting rounds)\n",
    "    \"learning_rate\": 0.01,  # Learning rate\n",
    "    \"max_depth\": 3,  # Maximum depth of each tree\n",
    "    \"min_child_weight\": 3,  # Minimum sum of instance weight (hessian) in a child\n",
    "    \"subsample\": 0.8,  # Proportion of training data used for each tree\n",
    "    \"colsample_bytree\": 0.8,  # Fraction of features used for each tree\n",
    "    \"gamma\": 0.1,  # Minimum loss reduction to make a further partition on a leaf node\n",
    "    \"reg_alpha\": 0,  # L1 regularization term\n",
    "    \"reg_lambda\": 0,  # L2 regularization term\n",
    "    \"seed\": 42,  # Random seed for reproducibility\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(**params)\n",
    "model.fit(X_train, y_train);\n",
    "models = XGBRegressor(**params)\n",
    "models.fit(X_trains, y_trains);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_preds = models.predict(X_tests)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "rmses = np.sqrt(mean_squared_error(y_tests, y_preds))\n",
    "print(\"RMSES:\", rmses)\n",
    "# print(\"Unscaled RMSE:\", np.exp(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = mean_absolute_percentage_error(y_pred,y_test)\n",
    "mapes = mean_absolute_percentage_error(y_preds,y_tests)\n",
    "print(mape,mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have RMSE values before and after scaling\n",
    "rmse_before = 26454.83716219436\n",
    "rmse_after = 0.8844200359201072\n",
    "\n",
    "# Calculate percentage reduction\n",
    "percentage_reduction = (rmse_before - rmse_after) / rmse_before * 100\n",
    "\n",
    "print(\"RMSE before scaling:\", rmse_before)\n",
    "print(\"RMSE after scaling:\", rmse_after)\n",
    "print(\"Percentage reduction:\", percentage_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.exp(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_before = 26454.83716219436\n",
    "rmse_after_log = 0.8844200359201072\n",
    "\n",
    "# Back-transform the RMSE\n",
    "rmse_after_original_scale = np.exp(rmse_after_log) - 1\n",
    "\n",
    "print(f\"RMSE before log transformation: {rmse_before}\")\n",
    "print(f\"RMSE after log transformation (back-transformed): {rmse_after_original_scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage errors\n",
    "def percentage_error(y_true, y_pred):\n",
    "    return (y_pred - y_true) / y_true * 100\n",
    "\n",
    "# Original model\n",
    "pe_original = percentage_error(y_test, y_pred)\n",
    "\n",
    "# Log-transformed model\n",
    "pe_log = percentage_error(np.exp(y_tests), np.exp(y_preds))  # Assuming y_tests and y_preds are log-transformed\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for the original model\n",
    "sns.histplot(pe_original, kde=True, ax=ax1)\n",
    "ax1.set_xlabel(\"Percentage Error (%)\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.set_title(\"Distribution of Percentage Errors: Original Model\")\n",
    "\n",
    "# Plot for the log-transformed model\n",
    "sns.histplot(pe_log, kde=True, ax=ax2)\n",
    "ax2.set_xlabel(\"Percentage Error (%)\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "ax2.set_title(\"Distribution of Percentage Errors: Log-transformed Model\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Original Model - Percentage Error Statistics:\")\n",
    "print(f\"Mean: {pe_original.mean():.2f}%\")\n",
    "print(f\"Median: {np.median(pe_original):.2f}%\")\n",
    "print(f\"Standard Deviation: {pe_original.std():.2f}%\")\n",
    "\n",
    "print(\"\\nLog-transformed Model - Percentage Error Statistics:\")\n",
    "print(f\"Mean: {pe_log.mean():.2f}%\")\n",
    "print(f\"Median: {np.median(pe_log):.2f}%\")\n",
    "print(f\"Standard Deviation: {pe_log.std():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for the original model\n",
    "sns.scatterplot(x=y_test, y=y_pred, ax=ax1)\n",
    "ax1.set_xlabel(\"Actual Values\")\n",
    "ax1.set_ylabel(\"Predicted Values\")\n",
    "ax1.set_title(\"Original Model: Actual vs. Predicted\")\n",
    "ax1.ticklabel_format(style='plain')\n",
    "\n",
    "# Plot for the log-transformed model\n",
    "sns.scatterplot(x=y_tests, y=y_preds, ax=ax2)\n",
    "ax2.set_xlabel(\"Actual Values (Log-transformed)\")\n",
    "ax2.set_ylabel(\"Predicted Values (Log-transformed)\")\n",
    "ax2.set_title(\"Log-transformed Model: Actual vs. Predicted\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def percentage_error(y_true, y_pred):\n",
    "    return (y_pred - y_true) / y_true * 100\n",
    "\n",
    "# Calculate percentage errors\n",
    "pe_original = percentage_error(y_test, y_pred)\n",
    "pe_log = percentage_error(np.exp(y_tests), np.exp(y_preds))  # Assuming y_tests and y_preds are log-transformed\n",
    "\n",
    "# Create a figure with six subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 24))\n",
    "\n",
    "# Scatter plot for original model\n",
    "axs[0, 0].scatter(y_test, y_pred)\n",
    "axs[0, 0].set_xlabel(\"Actual Values\")\n",
    "axs[0, 0].set_ylabel(\"Predicted Values\")\n",
    "axs[0, 0].set_title(\"Original Model: Actual vs. Predicted\")\n",
    "axs[0, 0].ticklabel_format(style='plain')\n",
    "\n",
    "# Scatter plot for log-transformed model\n",
    "axs[0, 1].scatter(y_tests, y_preds)\n",
    "axs[0, 1].set_xlabel(\"Actual Values (Log-transformed)\")\n",
    "axs[0, 1].set_ylabel(\"Predicted Values (Log-transformed)\")\n",
    "axs[0, 1].set_title(\"Log-transformed Model: Actual vs. Predicted\")\n",
    "\n",
    "# Percentage error distribution for original model\n",
    "sns.histplot(pe_original, kde=True, ax=axs[1, 0])\n",
    "axs[1, 0].set_xlabel(\"Percentage Error (%)\")\n",
    "axs[1, 0].set_ylabel(\"Frequency\")\n",
    "axs[1, 0].set_title(\"Distribution of Percentage Errors: Original Model\")\n",
    "\n",
    "# Percentage error distribution for log-transformed model\n",
    "sns.histplot(pe_log, kde=True, ax=axs[1, 1])\n",
    "axs[1, 1].set_xlabel(\"Percentage Error (%)\")\n",
    "axs[1, 1].set_ylabel(\"Frequency\")\n",
    "axs[1, 1].set_title(\"Distribution of Percentage Errors: Log-transformed Model\")\n",
    "\n",
    "# Feature importance for original model\n",
    "feature_importance_orig = model.feature_importances_\n",
    "axs[2, 0].bar(X_train.columns, feature_importance_orig)\n",
    "axs[2, 0].set_xlabel(\"Features\")\n",
    "axs[2, 0].set_ylabel(\"Importance\")\n",
    "axs[2, 0].set_title(\"Feature Importance: Original Model\")\n",
    "axs[2, 0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Feature importance for log-transformed model (assuming you have this)\n",
    "# If you don't have this, you can remove this subplot or duplicate the original model's feature importance\n",
    "feature_importance_log = models.feature_importances_  # Assuming you have this\n",
    "axs[2, 1].bar(X_trains.columns, feature_importance_log)\n",
    "axs[2, 1].set_xlabel(\"Features\")\n",
    "axs[2, 1].set_ylabel(\"Importance\")\n",
    "axs[2, 1].set_title(\"Feature Importance: Log-transformed Model\")\n",
    "axs[2, 1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Original Model - Percentage Error Statistics:\")\n",
    "print(f\"Mean: {pe_original.mean():.2f}%\")\n",
    "print(f\"Median: {np.median(pe_original):.2f}%\")\n",
    "print(f\"Standard Deviation: {pe_original.std():.2f}%\")\n",
    "\n",
    "print(\"\\nLog-transformed Model - Percentage Error Statistics:\")\n",
    "print(f\"Mean: {pe_log.mean():.2f}%\")\n",
    "print(f\"Median: {np.median(pe_log):.2f}%\")\n",
    "print(f\"Standard Deviation: {pe_log.std():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Plot the feature importance scores\n",
    "plt.bar(X_train.columns, feature_importance)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with y_pred and y_test as columns\n",
    "df_pred = pd.DataFrame({\"y_pred\": y_pred, \"y_test\": y_test})\n",
    "\n",
    "# Print the DataFrame\n",
    "df_pred[\"diff\"] = df_pred[\"y_test\"] - df_pred[\"y_pred\"]\n",
    "df_pred.head(20).apply(lambda x: x.apply('{0:.5f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.describe().apply(lambda x: x.apply('{0:.5f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.plot(kind='box')\n",
    "plt.title('Box Plot of Predicted Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-projects-l_2b9_F_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
